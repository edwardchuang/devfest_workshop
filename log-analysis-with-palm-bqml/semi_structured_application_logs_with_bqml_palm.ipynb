{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Copyright 2023 Google LLC.\n",
        "\n",
        "SPDX-License-Identifier: Apache-2.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1R1rfjGuV2i1"
      },
      "source": [
        "# **Semi-Structured Application Logs with BQML & PaLM**\n",
        "\n",
        "In this colab we'll go through how to connect and put the nginx access logs (from [Kaggle](https://www.kaggle.com/datasets/eliasdabbas/web-server-access-logs?resource=download&select=access.log)) to BigQuery and analysis via PaLM.\n",
        "\n",
        "Reference: https://cloud.google.com/bigquery/docs/generate-text-tutorial\n",
        "\n",
        "# **Costs**\n",
        "\n",
        "In this document, you use the following billable components of Google Cloud:\n",
        "\n",
        "* BigQuery: You incur costs for the data that you process in BigQuery, including query and storage.\n",
        "* Vertex AI: You incur costs for calls to the Vertex AI service that's represented by the remote model.\n",
        "* Cloud Storage: Your incur costs for storage staging access log file in JSON format before import into BigQuery.\n",
        "\n",
        "# **Workshop Format**\n",
        "\n",
        "This is a part of hands-on workshop of DevFest 2023\n",
        "\n",
        "Self Link: https://bit.ly/df23-log-analysis-bqml-palm\n",
        "\n",
        "For supplement materials, please refer to the [Presentation](https://www.google.com/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sp1ZwETyaL3O"
      },
      "source": [
        "# Setup\n",
        "\n",
        "Please login with same credential of your GCP project owner (or have enough permission to execute billable actions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzZTik6ua5Mc",
        "outputId": "4c34cdb5-5e58-47ed-84c0-6876de02cc22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Authenticated\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth as google_auth\n",
        "\n",
        "    google_auth.authenticate_user()\n",
        "    print(\"Authenticated\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Please modifiy following parameters to fits your own GCP environment, at least PROJECT_ID and GCS_BUCKET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmYUeLKIaPaI",
        "outputId": "76dd8413-9d1b-42a1-f2a4-7d097feed3a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Operation \"operations/acat.p2-436800949134-a97f82ad-ac90-457f-8ddc-2f2a7e368158\" finished successfully.\n"
          ]
        }
      ],
      "source": [
        "PROJECT_ID = 'colab-bqml-palm-demo' # @param {type:\"string\"}\n",
        "GCS_BUCKET = 'gs://colab-bqml-palm-demo' # @param {type:\"string\"}\n",
        "GCS_FILENAME = 'accesslog.json' # @param {type:\"string\"}\n",
        "BQ_DATASET_ID = 'kaggle_eliasdabbas_web_server_access_logs' # @param {type:\"string\"}\n",
        "BQ_TABLE_NAME = 'access_log' # @param {type:\"string\"}\n",
        "BQ_LOCATION = 'us' # @param {type:\"string\"}\n",
        "BQ_MODEL_NAME = 'colabs_llm' # @param {type:\"string\"}\n",
        "\n",
        "!gcloud services --project $PROJECT_ID \\\n",
        "  enable bigquery.googleapis.com \\\n",
        "  bigqueryconnection.googleapis.com \\\n",
        "  aiplatform.googleapis.com"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvmup3WIm2x9"
      },
      "source": [
        "# Prepare Datasource (1/3)\n",
        "\n",
        "*You may skip if you already done this part*\n",
        "\n",
        "* Download the data from https://www.kaggle.com/datasets/eliasdabbas/web-server-access-logs/download?datasetVersionNumber=2 (280MB, 3.5GB uncompressed)\n",
        "* Put access.log from the compress file above into your GCS bucket\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ygj_H7wPxCK5"
      },
      "source": [
        "# Approach 1 - Download from Kaggle\n",
        "\n",
        "Note: You need to signup Kggle and create your own API Token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "6SOpW6Nwweon",
        "outputId": "56056f40-46ce-4a72-ac7e-c176c6b65ff4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6e0e161e-155b-4eff-87fd-d7719222a284\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6e0e161e-155b-4eff-87fd-d7719222a284\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        }
      ],
      "source": [
        "# Note: You need to provide your Kaggle API token\n",
        "# Kaggle -> Account -> Create New Token (then you'll get kaggle.json)\n",
        "\n",
        "!pip install -q kaggle\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhw9V407wtFv",
        "outputId": "c1dd189d-2e16-46f3-b7fc-9d9d1f7be23d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading web-server-access-logs.zip to /content\n",
            " 96% 257M/267M [00:02<00:00, 40.2MB/s]\n",
            "100% 267M/267M [00:02<00:00, 95.4MB/s]\n",
            "Archive:  web-server-access-logs.zip\n",
            "  inflating: access.log              \n"
          ]
        }
      ],
      "source": [
        "!rm -fr web-server-access-logs.zip\n",
        "!kaggle datasets download -d eliasdabbas/web-server-access-logs\n",
        "!unzip -o web-server-access-logs.zip access.log\n",
        "!awk '{ gsub(/\"/, \"\\\\\\\"\"); print \"{\\\"payload\\\":\\\"\"$0\"\\\"}\"; }' access.log > accesslog.json\n",
        "!rm -fr access.log"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOxsVt20yM2X",
        "outputId": "14cbee45-dad5-474f-b91b-251588f744e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating gs://colab-bqml-palm-demo/...\n",
            "ServiceException: 409 A Cloud Storage bucket named 'colab-bqml-palm-demo' already exists. Try another name. Bucket names must be globally unique across all Google Cloud projects, including those outside of your organization.\n",
            "Copying file://accesslog.json [Content-Type=application/json]...\n",
            "==> NOTE: You are uploading one or more large file(s), which would run\n",
            "significantly faster if you enable parallel composite uploads. This\n",
            "feature can be enabled by editing the\n",
            "\"parallel_composite_upload_threshold\" value in your .boto\n",
            "configuration file. However, note that if you do this large files will\n",
            "be uploaded as `composite objects\n",
            "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
            "means that any user who downloads such objects will need to have a\n",
            "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
            "without a compiled crcmod, computing checksums on composite objects is\n",
            "so slow that gsutil disables downloads of composite objects.\n",
            "\n",
            "\\\n",
            "Operation completed over 1 objects/3.5 GiB.                                      \n"
          ]
        }
      ],
      "source": [
        "!gsutil mb -p $PROJECT_ID $GCS_BUCKET\n",
        "!gsutil -m cp $GCS_FILENAME $GCS_BUCKET\n",
        "!rm -fr $GCS_FILENAME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQAQhdEPxXhc"
      },
      "source": [
        "# Approach 2 - Download by yourself\n",
        "\n",
        "Browse and download from the Kaggle dataset above, uncompress it and upload `access.log` manually to the GCS bucket."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evWER6ryFAcT",
        "outputId": "1e997bc6-6167-4bd1-98da-1c0f20c74f88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "gs://colab-bqml-palm-demo/accesslog.json:\n",
            "    Creation time:          Fri, 22 Sep 2023 06:51:28 GMT\n",
            "    Update time:            Fri, 22 Sep 2023 06:51:28 GMT\n",
            "    Storage class:          STANDARD\n",
            "    Content-Length:         3730474167\n",
            "    Content-Type:           application/json\n",
            "    Hash (crc32c):          SzlPuQ==\n",
            "    Hash (md5):             G4HPKceGlSUyCExvXmtlhQ==\n",
            "    ETag:                   COPS0s3QvYEDEAE=\n",
            "    Generation:             1695365488486755\n",
            "    Metageneration:         1\n"
          ]
        }
      ],
      "source": [
        "!gsutil stat $GCS_BUCKET/$GCS_FILENAME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJQm0EPfVSyD"
      },
      "source": [
        "# Prepare Datasource (2/3)\n",
        "\n",
        "*You may skip if you already done this part*\n",
        "\n",
        "Load/Import the data from GCS bucket into BigQuery Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4vsOiLYHY-O",
        "outputId": "dea0e4fe-c0a6-4365-ad4f-cc4e97d550bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BigQuery error in mk operation: Dataset 'colab-bqml-palm-\n",
            "demo:kaggle_eliasdabbas_web_server_access_logs' already exists.\n",
            "Waiting on bqjob_r4895523e3cc46f17_0000018abba9e17f_1 ... (15s) Current status: DONE   \n"
          ]
        }
      ],
      "source": [
        "!bq --location=$BQ_LOCATION mk --dataset $PROJECT_ID:$BQ_DATASET_ID\n",
        "!bq --location=$BQ_LOCATION \\\n",
        "    --project_id=$PROJECT_ID \\\n",
        "    load \\\n",
        "    --replace \\\n",
        "    --source_format=NEWLINE_DELIMITED_JSON \\\n",
        "    --schema='payload:STRING' \\\n",
        "    $PROJECT_ID:$BQ_DATASET_ID\".\"$BQ_TABLE_NAME \\\n",
        "    $GCS_BUCKET'/'$GCS_FILENAME\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIyH6y7FwIoZ"
      },
      "source": [
        "# Create BigLake (3/3)\n",
        "\n",
        "*You may skip if you already done this part*\n",
        "\n",
        "Create BigLake and remote functions (Cloud Resource)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXkIqJIPy2fF",
        "outputId": "fb9b8954-5c22-46df-bcc5-bede036b2839"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Connection 436800949134.us.colab_biglake successfully created\n"
          ]
        }
      ],
      "source": [
        "!bq mk \\\n",
        "  --connection \\\n",
        "  --location=$BQ_LOCATION \\\n",
        "  --project_id=$PROJECT_ID \\\n",
        "  --connection_type=CLOUD_RESOURCE \\\n",
        "  colab_biglake"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MKgRvlcznv-",
        "outputId": "c3d91e70-5003-41a9-c268-601c21a727aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Updated IAM policy for project [colab-bqml-palm-demo].\n",
            "bindings:\n",
            "- members:\n",
            "  - serviceAccount:service-436800949134@gcp-sa-aiplatform-cc.iam.gserviceaccount.com\n",
            "  role: roles/aiplatform.customCodeServiceAgent\n",
            "- members:\n",
            "  - serviceAccount:service-436800949134@gcp-sa-aiplatform-vm.iam.gserviceaccount.com\n",
            "  role: roles/aiplatform.notebookServiceAgent\n",
            "- members:\n",
            "  - serviceAccount:service-436800949134@gcp-sa-aiplatform.iam.gserviceaccount.com\n",
            "  role: roles/aiplatform.serviceAgent\n",
            "- members:\n",
            "  - deleted:serviceAccount:bqcx-436800949134-6v0l@gcp-sa-bigquery-condel.iam.gserviceaccount.com?uid=112471142346029776235\n",
            "  - deleted:serviceAccount:bqcx-436800949134-xbui@gcp-sa-bigquery-condel.iam.gserviceaccount.com?uid=107342139465376552440\n",
            "  - serviceAccount:bqcx-436800949134-1wug@gcp-sa-bigquery-condel.iam.gserviceaccount.com\n",
            "  role: roles/aiplatform.user\n",
            "- members:\n",
            "  - user:admin@pingda.altostrat.com\n",
            "  role: roles/billing.projectManager\n",
            "- members:\n",
            "  - serviceAccount:service-436800949134@compute-system.iam.gserviceaccount.com\n",
            "  role: roles/compute.serviceAgent\n",
            "- members:\n",
            "  - serviceAccount:service-436800949134@gcp-sa-dataform.iam.gserviceaccount.com\n",
            "  role: roles/dataform.serviceAgent\n",
            "- members:\n",
            "  - serviceAccount:436800949134@cloudservices.gserviceaccount.com\n",
            "  - user:pingda@altostrat.com\n",
            "  role: roles/editor\n",
            "- members:\n",
            "  - user:edwardc@pingda.altostrat.com\n",
            "  role: roles/owner\n",
            "etag: BwYF7RF2wCI=\n",
            "version: 1\n"
          ]
        }
      ],
      "source": [
        "!DEBIAN_FRONTEND=noninteractive apt-get -y -qq install --upgrade jq\n",
        "BQ_CONNECTION_SA_ = !bq show \\\n",
        "  --connection \\\n",
        "  --project_id=$PROJECT_ID \\\n",
        "  --location=$BQ_LOCATION \\\n",
        "  --format=prettyjson \\\n",
        "  colab_biglake | jq -r '.cloudResource.serviceAccountId'\n",
        "BQ_CONNECTION_SA = BQ_CONNECTION_SA_[0]\n",
        "!gcloud projects \\\n",
        "  add-iam-policy-binding \\\n",
        "  $PROJECT_ID \\\n",
        "  --member='serviceAccount:'$BQ_CONNECTION_SA \\\n",
        "  --role='roles/aiplatform.user'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmM_GZTh-aJr"
      },
      "source": [
        "# Create a Model on BigQuery"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBEI5OPe-kmW",
        "outputId": "ee8cfa11-7f86-4183-82cc-e8b134051584"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Created: kaggle_eliasdabbas_web_server_access_logs.colabs_llm\n"
          ]
        }
      ],
      "source": [
        "from google.cloud import bigquery\n",
        "\n",
        "client = bigquery.Client(project=PROJECT_ID)\n",
        "sql_query = \"\"\"\n",
        "CREATE OR REPLACE MODEL\n",
        "    `{bq_dataset_id}.{bq_model_name}`\n",
        "    REMOTE WITH CONNECTION `{project_id}.{bq_location}.colab_biglake`\n",
        "    OPTIONS (REMOTE_SERVICE_TYPE=\"CLOUD_AI_LARGE_LANGUAGE_MODEL_V1\");\n",
        "\"\"\".format(bq_dataset_id=BQ_DATASET_ID,\n",
        "           project_id=PROJECT_ID,\n",
        "           bq_location=BQ_LOCATION,\n",
        "           bq_model_name=BQ_MODEL_NAME)\n",
        "\n",
        "job = client.query(sql_query)\n",
        "job.result()\n",
        "\n",
        "if job.state == 'DONE':\n",
        "  print(\"Model Created: %s.colabs_llm\" % (BQ_DATASET_ID))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgH_b2UcgvZ_"
      },
      "source": [
        "# Let's do some real query!\n",
        "\n",
        "*Note: If you experiences permission issues for executing the query, kindly wait few more minutes until IAM settings are propagated*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lv6tZMoLhFsq",
        "outputId": "7e11699d-71cd-4c22-df28-373e70b25a7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prompt: Desktop or mobile browser?: 10.249.34.197 - - [23/Jan/2019:13:34:17 +0330] \"GET /image/64998/productModel/150x150 HTTP/1.1\" 200 4997 \"https://www.zanbil.ir/filter/p62,stexists\" \"Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36\" \"-\"\n",
            "Result:  Desktop\n",
            "\n",
            "Prompt: Desktop or mobile browser?: 104.156.210.198 - - [25/Jan/2019:02:34:31 +0330] \"POST /ajaxFilter/p28609,b136 HTTP/1.1\" 200 4121 \"https://www.zanbil.ir/filter/p28609\" \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36\" \"-\"\n",
            "Result:  Desktop\n",
            "\n",
            "Prompt: Desktop or mobile browser?: 104.194.24.17 - - [25/Jan/2019:10:37:23 +0330] \"GET /image/399/brand HTTP/1.1\" 200 2302 \"https://www.zanbil.ir/browse/wall-oven/%D9%81%D8%B1-%D8%AA%D9%88%DA%A9%D8%A7%D8%B1\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:64.0) Gecko/20100101 Firefox/64.0\" \"-\"\n",
            "Result:  Desktop\n",
            "\n",
            "Prompt: Desktop or mobile browser?: 104.194.24.190 - - [22/Jan/2019:15:36:42 +0330] \"GET /static/images/Icon-Buypage/addToZanbil-box.png HTTP/1.1\" 200 4011 \"https://znbl.ir/static/bundle-bundle_site_head.css\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:64.0) Gecko/20100101 Firefox/64.0\" \"-\"\n",
            "Result:  Desktop\n",
            "\n",
            "Prompt: Desktop or mobile browser?: 104.194.25.120 - - [26/Jan/2019:13:21:21 +0330] \"GET /image/65122/productModel/150x150 HTTP/1.1\" 200 4344 \"https://www.zanbil.ir/event/Casio-Violet\" \"Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36\" \"-\"\n",
            "Result:  Desktop\n",
            "\n",
            "Prompt: Desktop or mobile browser?: 104.222.32.82 - - [26/Jan/2019:17:22:59 +0330] \"GET /image/8864/specialSale?role=e1 HTTP/1.1\" 200 11 \"https://www.zanbil.ir/filter/b878\" \"Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36\" \"-\"\n",
            "Result:  Desktop\n",
            "\n",
            "Prompt: Desktop or mobile browser?: 104.222.32.84 - - [23/Jan/2019:10:28:51 +0330] \"GET /static/bundle-bundle_admin_defer.min.js HTTP/1.1\" 200 89664 \"https://www.zanbil.ir/orderAdministration/console/187337\" \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:64.0) Gecko/20100101 Firefox/64.0\" \"-\"\n",
            "Result:  Desktop\n",
            "\n",
            "Prompt: Desktop or mobile browser?: 104.222.32.91 - - [26/Jan/2019:10:44:59 +0330] \"GET /static/bundle-bundle_jqGrid_head.min.css HTTP/1.1\" 200 2260 \"https://www.zanbil.ir/orderAdministration/console/187857\" \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:64.0) Gecko/20100101 Firefox/64.0\" \"-\"\n",
            "Result:  Desktop\n",
            "\n",
            "Prompt: Desktop or mobile browser?: 104.222.32.91 - - [26/Jan/2019:14:02:28 +0330] \"GET /static/bundle-bundle_jqGrid_head.min.css HTTP/1.1\" 200 2260 \"https://www.zanbil.ir/orderAdministration/console/188011\" \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:64.0) Gecko/20100101 Firefox/64.0\" \"-\"\n",
            "Result:  Desktop\n",
            "\n",
            "Prompt: Desktop or mobile browser?: 104.248.136.173 - - [24/Jan/2019:07:56:18 +0330] \"GET /settings/logo HTTP/1.1\" 200 4120 \"https://www.zanbil.ir/\" \"Mozilla/5.0 (iPhone; CPU iPhone OS 12_1_2 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/12.0 Mobile/15E148 Safari/604.1\" \"-\"\n",
            "Result:  Mobile browser\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# @title Ask for client's platform type\n",
        "prompt = \"Desktop or mobile browser?\" # @param {type:\"string\"}\n",
        "payload_limit = 10 # @param {type:\"integer\"}\n",
        "temperature = 0.2 # @param {type:\"number\"}\n",
        "max_output_tokens = 650 # @param {type:\"integer\"}\n",
        "top_p = 0.2 # @param {type:\"number\"}\n",
        "top_k = 15 # @param {type:\"number\"}\n",
        "\n",
        "from google.cloud import bigquery\n",
        "import json\n",
        "\n",
        "client = bigquery.Client(project=PROJECT_ID)\n",
        "\n",
        "sql_query = \"\"\"\n",
        "SELECT *\n",
        "FROM\n",
        "  ML.GENERATE_TEXT(\n",
        "    MODEL `{bq_dataset_id}.{bq_model_name}`,\n",
        "    (\n",
        "      SELECT CONCAT('{prompt}: ', a.payload) AS prompt,\n",
        "      *\n",
        "      FROM `{bq_dataset_id}.{bq_table_name}` as a\n",
        "      LIMIT {payload_limit}\n",
        "    ),\n",
        "    STRUCT(\n",
        "      {temperature} AS temperature,\n",
        "      {max_output_tokens} AS max_output_tokens,\n",
        "      {top_p} AS top_p,\n",
        "      {top_k} AS top_k\n",
        "    )\n",
        "  );\n",
        "\"\"\".format(\n",
        "    bq_dataset_id=BQ_DATASET_ID,\n",
        "    bq_table_name=BQ_TABLE_NAME,\n",
        "    bq_location=BQ_LOCATION,\n",
        "    bq_model_name=BQ_MODEL_NAME,\n",
        "    payload_limit=payload_limit,\n",
        "    prompt=prompt,\n",
        "    temperature=temperature,\n",
        "    max_output_tokens=max_output_tokens,\n",
        "    top_p=top_p,\n",
        "    top_k=top_k)\n",
        "\n",
        "job = client.query(sql_query)\n",
        "results = job.result()\n",
        "\n",
        "for row in results:\n",
        "  _result = json.loads(row['ml_generate_text_result'])\n",
        "  print(\"\"\"Prompt: {prompt}\n",
        "Result: {result}\n",
        "\"\"\".format(\n",
        "    prompt=row['prompt'],\n",
        "    result=_result['predictions'][0]['content'])\n",
        ")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
